---
title: 'STA 5207: Homework 8'
date: 'Due: Friday, March 22 by 11:59 PM'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Include your R code in an R chunks as part of your answer. In addition, your written answer to each exercise should be self-contained so that the grader can determine your solution without reading your code or deciphering its output.

## Exercise 1 (The `divusa` Data Set) [50 points]

For this exercise, we will use the `divusa` data set from the `faraway` package. You can also find the data in `divusa.csv` on Canvas. The data set contains information on divorce rates in the USA from 1920 to 1996. The variables in the data set are

-   `year`: the year from 1920-1996.

-   `divorce`: divorce per 1000 women aged 15 or more.

-   `unemployed`: unemployment rate.

-   `femlab`: female participation in labor force aged 16+.

-   `marriage`: marriages per 1000 unmarried women aged 16+.

-   `birth`: births per 1000 women aged 15-44.

-   `military`: military personnel per 1000 population.

In the following exercise, we will model the `divorce` variable in terms of `unemployed`, `femlab`, `marriage`, `birth`, and `military`.

1.  (2 points) The variable `year` is not being used in the model, but it shows that the measurements were taken across time. What does this make you suspect about the error term? No output need.

    **Answer:** This makes me suspect that the errors do not have equal variance. The data from year i is most likely dependent on the data from year i-1.

2.  (6 points) Fit an OLS regression model with `divorce` as the response and all other variables except `year` as predictors. Check for serial correlation in the errors using a graphical method. Do you feel like the errors are serially correlated? Justify your answer. Include any plots in your response.

    ```{r}
    library(faraway)

    data(divusa, package='faraway')

    model_ols <- lm(divorce~.-year, data=divusa)

    plot(divusa$year, resid(model_ols), pch=20, xlab='time', ylab='residuals')
    ```

    **Answer:** Yes, I feel like the errors are serially correlated. I plotted the residuals of the OLS model excluding 'year' vs. the attribute 'year' and there seems to be a clear correlation between the two.

3.  (6 points) Check for the presence of serial correlation in the errors using the Durbin-Watson test. Report the following:

    -   The null and alternative hypotheses.
    -   The value of the test statistic.
    -   The $p$-value of the test.
    -   A statistical decision at the $\alpha = 0.05$ significance level.

    ```{r}
    library(lmtest)

    dwtest(model_ols, alternative = 'two.sided')
    ```

    **Answer:** The test statistic is 0.2999 with a p-value of 2.2e-16. We reject the null hypothesis and concluded the errors follow an AR(1) process.

4.  (10 points) Model the serial correlation with an AR(1) process, meaning that $\Sigma_{ij} = \phi^{|i-j|}$. Use the ML method to estimate the parameters in the GLS fit. Create and report a table with the OLS estimates (model in part 2) and GLS estimates for the slope parameters.

    ```{r}
    library(nlme)

    model_gls <- gls(divorce ~ . - year, 
                    correlation = corAR1(form = ~ year),
                    method = 'ML', data = divusa)

    ols_estimates <- coef(model_ols)
    gls_estimates <- coef(model_gls)

    data.frame(OLS = ols_estimates, GLS = gls_estimates)
    ```

    **Answer:** Above is a table with OLS and GLS estimates for the slope parameters.

5.  (10 points) Perform a $t$-test at the 5% significance level for each slope parameter for the OLS model in part 2 and the GLS model in part 4. Are there differences between which predictors are significant in the OLS model and which are significant in the GLS model? If so, state the changes.

    ```{r}
    summary(model_ols)$coefficients
    coef(summary(model_gls))
    ```

    **Answer:** The predictors that are significant in the OLS model (predictors with a p-value \< 0.05) are femlab, marriage, and birth. The predictors that are significant in the GLS model are unemployed, femlab, marriage, and birth. The predictor "unemployed" is significant in the GLS model but not in the OLS model.

6.  (5 points) For the GLS model in part 4, calculate and report the variance inflation factor (VIF) for each of the predictors using the `vif` function from the `car` package. Do any of these VIFs suggest we should be cautious about concluding a variable is “not significant” given the other predictors?

    ```{r}
    library(car)

    car::vif(model_gls)
    ```

    **Answer:** We are looking for predictors that have VIFs larger than 5. Since none of these predictors have VIFs larger than 5, we do not need to be cautious about concluding a variable is “not significant” given the other predictors.

7.  (5 points) Report the estimated value of the autocorrelation parameter $\phi$ and its associated 95% confidence interval. Does the interval indicate that $\phi$ is significantly different from zero at the 5% significance level?

    ```{r}
    intervals(model_gls)
    ```

    **Answer:** We get a value of $\hat\phi=0.972$ with a confidence interval of (0.653, 0.998). This interval does not cover zero, so we conclude that $\phi$ is significantly greater than zero, i.e., there is significant autocorrelation in the data.

8.  (6 points) Check for serial correlation in the normalized errors of the GLS model in part 4 using a graphical method. Do you feel like the normalized errors are serially correlated? Justify your answer. Include any plots in your response.

    ```{r}
    plot(divusa$year, resid(model_gls), pch=20, xlab='time', ylab='residuals')
    ```

    **Answer:** Yes, I feel like the errors are serially correlated. I plotted the residuals of the GLS model excluding 'year' vs. the attribute 'year' and there seems to be a clear correlation between the two.

## Exercise 2 (The `gala` Data Set) [40 points]

For this exercise, we will use the `gala` data set from the `faraway` package. You can also find the data set in `gala.csv` on Canvas. The data set contains the following variables:

-   `Species`: The number of plant species found on the island.

-   `Area`: The area of the island ($\text{km}^2$).

-   `Elevation`: The highest elevation of the island (m).

-   `Nearest`: The distance from the nearest island (km).

-   `Scruz`: The distance from Santa Cruz island (km).

-   `Adjacent`: The area of the adjacent island ($\text{km}^2$).

In the following exercise, we will model `Species` in terms of `Area`, `Elevation`, and `Nearest`.

1.  (5 points) Perform OLS regression with `Species` as the response and `Area`, `Elevation`, and `Nearest` as the predictors. Check the constant variance assumption for this model using a graphical method and a hypothesis test at the $\alpha = 0.05$ significance level. Do you feel it has been violated? Justify your answer. Include any plots in your response.

    ```{r}
    library(olsrr)
    library(lmtest)

    data(gala, package='faraway')
    model_ols <- lm(Species ~ Area + Elevation + Nearest, data=gala)
    ols_plot_resid_fit(model_ols)
    bptest(model_ols)
    ```

    **Answer:** Looking at the graph, the errors seem to be heteroscedastic. Upon performing a Breush-Pagan test, we get a p-value of 0.011. At a the $\alpha = 0.05$ significance level, we reject the null hypothesis and conclude that the errors are heteroscedastic and thus do not have constant variance.

2.  (8 points) Perform a regression of the absolute value of the residuals from the model in part 1 against the predictors `Area`, `Elevation`, and `Nearest` using OLS. Report the estimated regression equation using all 3 predictors.

    ```{r}
    model_wts <- lm(abs(resid(model_ols))~Area+Elevation+Nearest,data=gala)

    coef(model_wts)
    ```

    **Answer:** The estimated regression equation using all 3 predictors is $|e_i|=5.868-0.036area_i+0.143elevation_i-0.256nearest_i$

3.  (8 points) Perform WLS using the inverse of the squared fitted values from the model in part 2 as weights, i.e, $\texttt{weights} = 1/\text{(fitted values)}^2$. Create and report a table with the OLS estimates (model in part 1) and WLS estimates for the slope parameters.

    ```{r}
    weights = 1 / fitted(model_wts)^2

    model_wls = lm(Species~Area+Elevation+Nearest, data=gala, weights=weights)

    ols_estimates <- coef(model_ols)
    wls_estimates <- coef(model_wls)

    data.frame(OLS = ols_estimates, WLS = wls_estimates)
    ```

    **Answer:** Above is a table with the OLS and WLS estimates for the slope parameters.

4.  (8 points) Perform a $t$-test at the 5% significance level for each slope parameter for the OLS model in part 1 and the WLS model in part 3. Are there differences between which predictors are significant in the OLS model and which are significant in the WLS model? If so, state the changes.

    ```{r}
    summary(model_ols)$coefficients
    coef(summary(model_wls))
    ```

    **Answer:** The predictors that are significant in the OLS model (predictors with a p-value \< 0.05) is only Elevation. The predictors that are significant in the WLS model are Elevation and Nearest. The predictor "Nearest" is significant in the WLS model but not in the OLS model.

5.  (5 points) For the WLS model in part 3, calculate and report the variance inflation factor (VIF) for each of the predictors using the `vif` function from the `car` package. Do any of these VIFs suggest we should be cautious about concluding a variable is “not significant” given the other predictors?

    ```{r}
    car::vif(model_wls)
    ```

    **Answer:** We are looking for predictors that have VIFs larger than 5. Since none of these predictors have VIFs larger than 5, we do not need to be cautious about concluding a variable is “not significant” given the other predictors.

6.  (6 points) Check the constant variance assumption on the weighted residuals of the WLS model using a a graphical method and a hypothesis test at the $\alpha = 0.05$ significance level. Do you feel that it has been violated? Justify your answer. Include any plots in your response.

    ```{r}
    plot(fitted(model_wls), weighted.residuals(model_wls), 
         pch = 20, xlab = 'Fitted Value', ylab = 'Weighted Residual')
    abline(h=0, lwd=3, col='steelblue')
    bptest(model_wls)
    ```

    **Answer:** The errors look to have constant variance and the p-value of 1 supports this due to it being greater than 0.05. Therefore we do not reject the null and assume

## Exercise 3 (WLS for Survey Data) [10 points]

For this exercise, we will use the the `chibus` data set, which can be found in `chibus.csv` on Canvas. Each observation in this data set represents a pair of zones in the city of Chicago. The variables in the data set are

-   `computed_time`: travel times, computed from bus timetables augmented by walk times from zone centers to bus-stops (assuming a walking speed of 3 mph) and expected waiting times for the bus (= half of the time between successive buses).

-   `perceived_time`: average travel times as reported to the U.S. Census Bureau by $n$ travelers.

-   `n`: number of travelers per observations for each case.

In the following exercise, we will model `perceived_time` in terms of `computed_time`.

1.  (5 points) The variable `n` is not being used in the model, but it shows that the response is recorded as an average over different groups of size $n_i$. Based on this observation, what would make for a good choice of weights? No output is needed.

    **Answer:** We should use n_i as our weights.

2.  (5 points) Perform WLS with `perceived_time` as the response and `computed_time` as the predictor using the weights you chose in part 1. Report the estimated regression equation for this model.

    ```{r}
    data <- read.csv('chibus.csv')

    wls_model <- lm(perceived_time ~ computed_time, data = data, weights = n)
    summary(wls_model)
    ```

    **Answer:** Our estimated regression equation for this model is $y=2.293+1.132computedtime$ .
